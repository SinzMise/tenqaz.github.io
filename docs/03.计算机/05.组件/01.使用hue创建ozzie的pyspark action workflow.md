---
categories: 
  - 计算机
  - 组件
tags: 
  - hue
  - python
  - 大数据
title: 使用hue创建ozzie的pyspark action workflow
date: 2022-08-10 00:00:00
permalink: /pages/aba491/
author: 
  name: zhengwenfeng
  link: https://github.com/tenqaz
description: null
feed: 
  enable: true
---



>hue是一个Apache Hadoop ui系统，本篇文章介绍如何使用hue创建一个ozzie的pyspark action的workflow, 该workflow仅包含一个spark action。注意，本文使用的是python语言的pyspark。


1. 编写一个python操作spark的程序。
demo.py
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.enableHiveSupport().appName(
"demo").getOrCreate()

# spark 的一些操作
.......

```

2. 新建workflow

![](https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215736.png)
![](https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215850.png)

>传入需要运行的python脚本

![](https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215907.png)

3. 对该action 进行一些属性的配置。
![](https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215929.png)

> 对spark进行设置，可以选择spark的运行模式。
> 默认使用的是spark1 的库去执行，如果使用的是spark2，则需要设置属性`oozie.action.sharelib.for.spark=spark2` 如图所示。

![](https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215946.png)

> 进入2设置，进行一些变量的设置
> oozie.libpath 需要使用到spark的一些jar包，填入路径jar包路径。

![](https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215946.png)

4. 该workflow已经设置成功，可以对其进行运行进行测试。